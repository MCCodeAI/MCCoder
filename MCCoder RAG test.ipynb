{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC Code RAG Workshop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector base and RAG test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p1=0  #Parameter 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai chromadb bs4 python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key from .env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "# Use this line of code if you have a local .env file\n",
    "load_dotenv(find_dotenv()) \n",
    "\n",
    "# Or set it like this\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "\n",
    "# Print this line to double check your API key\n",
    "# print(os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith(enabled by default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls__7cb2a18f629e4c10b5a34d49223fba88\n"
     ]
    }
   ],
   "source": [
    "# Store all the keys in .env\n",
    "import getpass\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.environ[\"LANGCHAIN_API_KEY\"] #getpass.getpass()\n",
    "print(os.environ[\"LANGCHAIN_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader, TextLoader, PyPDFLoader, PyPDFium2Loader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web loader\n",
    "# loader = WebBaseLoader(\n",
    "#     web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "#     bs_kwargs=dict(\n",
    "#         parse_only=bs4.SoupStrainer(\n",
    "#             class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "#         )\n",
    "#     ),\n",
    "# )\n",
    "# docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pdf loader\n",
    "file_path = './docs/WMX3SampleCodes.pdf'\n",
    "# file_path = 'nais2023.pdf'\n",
    "# loader = PyPDFLoader(file_path)\n",
    "# loader = PyPDFLoader(file_path, extract_images=True)   #extract images as text as well\n",
    "\n",
    "loader = PyPDFium2Loader(file_path,  extract_images=False) \n",
    "# docs = loader.load_and_split()\n",
    "docs = loader.load()\n",
    "print(docs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Txt loader\n",
    "loader = TextLoader(\"./docs/WMX3UserManual_a.txt\")\n",
    "docs = loader.load()\n",
    "# docs[0].page_content[:100000]\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Txt loader\n",
    "loader = TextLoader(\"./docs/WMX3SampleCodes.py\")\n",
    "docs = loader.load()\n",
    "# docs[0].page_content[:100000]\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Txt loader for api with instruction\n",
    "loader = TextLoader(\"./docs/WMX3API_CleanedData.json\")\n",
    "docs = loader.load()\n",
    "# docs[0].page_content[:100000]\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WMX3manual text chunk \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, add_start_index=True)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample code chunk with `` separators\n",
    "separators = ['``']  # Adjust based on actual document structure\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=separators, keep_separator=True, chunk_size=1000, chunk_overlap=200, add_start_index=True)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample code chunk with } separators -api with instruction, WMX3API_CleanedData.json\n",
    "separators = ['}']  # Adjust based on actual document structure\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=separators, keep_separator=True, chunk_size=1000, chunk_overlap=200, add_start_index=True)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Main \\n\\n\\nThis help file contains information regarding the functions that are available in WMX3. \\nUse the links to the left to navigate through this help file. \\n \\n\\nSupport Specifications \\n\\n\\nWMX3 RTX Version \\n\\n \\n\\n\\nWMX3 RTX Version \\n\\n\\nSupported PC Hardware \\nSupported OS \\nSupported NIC \\nSupported Library and IDE \\nSupported Sample Project \\nSupport for user application development running only on a real-time OS \\nSupport for user application development running only on a non real-time \\nOS \\n \\n\\n\\nSupported PC Hardware \\n\\nTo operate WMX3, a PC with the following specifications is required. \\n\\nCPU \\nRequirement', metadata={'source': './docs/WMX3UserManual_a.txt', 'start_index': 0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Supported PC Hardware \\n\\nTo operate WMX3, a PC with the following specifications is required. \\n\\nCPU \\nRequirement \\n\\n\\nPerformance : A CPU with performance of at least the Atom E3845 (2GHz) is \\nrequired. \\nNumber of cores : Since it is necessary to assign a dedicated CPU core to RTX, a \\nminimum of 2 cores (excluding Hyper-Threading virtual cores) is required. \\nGeneration : Each version of RTX supports specific CPU generations. Select the \\nCPU based on the compatibility information below. CPUs that are not listed in the \\ncompatibility information are not supported at that time. \\nFor additional information, please refer to the following technical note of IntervalZero \\n(the developer of RTX). \\n\\nhttp://softservo.com/pub/RTX_Doc/RTX64/Manual/RTX64_Processor_Compatibility.pdf \\n\\nRecommended', metadata={'source': './docs/WMX3UserManual_a.txt', 'start_index': 492})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(RecursiveCharacterTextSplitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorstore - chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model=OpenAIEmbeddings(model=\"text-embedding-3-large\")   #text-embedding-3-large   #text-embedding-ada-002    #text-embedding-3-small\n",
    "\n",
    "# If txt vectorstore exists\n",
    "# if os.path.exists(\"Vectorstore/chromadb-MCCoder\"):\n",
    "        # vectorstore = Chroma(\n",
    "                #     embedding_function=embedding_model,\n",
    "                #     persist_directory=\"Vectorstore/chromadb\",\n",
    "                #     ) \n",
    "# else:\n",
    "        # Load from chunks and save to disk\n",
    "        # vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model, persist_directory=\"Vectorstore/chromadb\") \n",
    "\n",
    "# If vectorstore exists\n",
    "vectorstore_path = \"Vectorstore/chromadb-MCCoder\"\n",
    " # Load from chunks and save to disk\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model,  persist_directory=vectorstore_path) \n",
    "# if os.path.exists(vectorstore_path):\n",
    "#         vectorstore = Chroma(\n",
    "#                     embedding_function=embedding_model,\n",
    "#                     persist_directory=vectorstore_path,\n",
    "#                     ) \n",
    "# else:\n",
    "#         # Load from chunks and save to disk\n",
    "#         vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model, persist_directory=vectorstore_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "# retriever = vectorstore.similarity_search_with_score('a typical python code of WMX3 for a axis/servo/motor to move or do positioning.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x10fa47ad0>, search_kwargs={'k': 4})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Supported PC Hardware \\n\\nTo operate WMX3, a PC with the following specifications is required. \\n\\nCPU \\nRequirement \\n\\n\\nPerformance : A CPU with performance of at least the Atom E3845 (2GHz) is \\nrequired. \\nNumber of cores : Since it is necessary to assign a dedicated CPU core to RTX, a \\nminimum of 2 cores (excluding Hyper-Threading virtual cores) is required. \\nGeneration : Each version of RTX supports specific CPU generations. Select the \\nCPU based on the compatibility information below. CPUs that are not listed in the \\ncompatibility information are not supported at that time. \\nFor additional information, please refer to the following technical note of IntervalZero \\n(the developer of RTX). \\n\\nhttp://softservo.com/pub/RTX_Doc/RTX64/Manual/RTX64_Processor_Compatibility.pdf \\n\\nRecommended', metadata={'source': './docs/WMX3UserManual_a.txt', 'start_index': 492}),\n",
       " Document(page_content='Generation : Intel 2nd gen or later, Corei3, Corei5, Corei7 are recommended. \\nMemory (RAM) \\n\\nRequirement \\n\\n\\n2GB or more is required. \\nRecommended \\n\\n\\n4GB or more is recommended. \\n\\n \\n\\nSupported OS \\n\\nWMX3 RTX Version supports the following versions of Windows. \\nThe list includes three support status: \\n\\nNotati \\non Condition \\nSupported and recommended \\n: \\nSupported \\n× \\nNot supported \\n\\n64-bit OS', metadata={'source': './docs/WMX3UserManual_a.txt', 'start_index': 2227}),\n",
       " Document(page_content='Main \\n\\n\\nThis help file contains information regarding the functions that are available in WMX3. \\nUse the links to the left to navigate through this help file. \\n \\n\\nSupport Specifications \\n\\n\\nWMX3 RTX Version \\n\\n \\n\\n\\nWMX3 RTX Version \\n\\n\\nSupported PC Hardware \\nSupported OS \\nSupported NIC \\nSupported Library and IDE \\nSupported Sample Project \\nSupport for user application development running only on a real-time OS \\nSupport for user application development running only on a non real-time \\nOS \\n \\n\\n\\nSupported PC Hardware \\n\\nTo operate WMX3, a PC with the following specifications is required. \\n\\nCPU \\nRequirement', metadata={'source': './docs/WMX3UserManual_a.txt', 'start_index': 0}),\n",
       " Document(page_content='*The products that have been tested are only the following hardware IDs and chipsets. \\n\\nPCI\\\\VEN_10EC&DEV_8168&SUBSYS_83A31043&REV_03 \\nPCI\\\\VEN_10EC&DEV_8168&SUBSYS_816810EC&REV_03 \\nPCI\\\\VEN_10EC&DEV_8168&SUBSYS_816810EC&REV_02 \\nPCI\\\\VEN_10EC&DEV_8168&SUBSYS_2A90103C&REV_03 \\nPCI\\\\VEN_10EC&DEV_8168&SUBSYS_012310EC&REV_02 \\nRealtek 8168C Spin 2 \\nRealtek 8168C \\nRealtek 8168CP \\nRealtek 8168D \\n\\nRt8257x_SSS.rtdll \\n\\nVendo \\nr ID \\nDevice \\nID Device Name RTX \\n3.x \\nRTX \\n4.x Remarks \\n0x8086 0x10c9 Intel 82576 Gigabit ET/ET2/EF Server Adapter : \\n: \\n0x8086 0x1526 Intel Gigabit ET2 Quad Port Server Adapter \\n0x8086 0x10A7 Intel 82575EB Gigabit Ethernet Controller \\n0x8086 0x10e6 Intel 82576 Gigabit ET/ET2/EF Server Adapter \\n0x8086 0x10e7 Intel 82576 Gigabit ET/ET2/EF Server Adapter \\n\\n\\nRt82580_SSS.rtdll', metadata={'source': './docs/WMX3UserManual_a.txt', 'start_index': 14695})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieved_docs = retriever.invoke(\"a typical python code of WMX3 for a axis/servo/motor to move or do positioning. \")\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"Supported PC Hardware \")\n",
    "\n",
    "#print(retrieved_docs[0].page_content)\n",
    "retrieved_docs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorstore - pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "index_name = os.environ[\"PINECONE_INDEX_NAME\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PineconeVectorStore.delete(delete_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docsearch = PineconeVectorStore.from_documents(splits, embedding_model, index_name=index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = PineconeVectorStore.from_existing_index(index_name, embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is the Architecture of wmx3?\"\n",
    "retrieved_docs = docsearch.similarity_search(query,k=8)\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorstore - FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model=OpenAIEmbeddings(model=\"text-embedding-3-large\")   \n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstore_path = \"Vectorstore/FAISS-pdf-images\"\n",
    "db = FAISS.from_documents(splits, embedding_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local(folder_path=\"Vectorstore/FAISS-pdf-images\", index_name=\"myFaissIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.load_local(folder_path=\"Vectorstore/FAISS-pdf-images\",embeddings=embedding_model,index_name=\"myFaissIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"a typical python code of WMX3 for a axis/servo/motor to move or do positioning.\"\n",
    "docs = db.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorstore - pathway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### serve Maximum marginal relevance search (MMR) Similarity search by vector ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "qdrant = Qdrant.from_documents(\n",
    "    splits,\n",
    "    embedding_model,\n",
    "    path=\"Vectorstore/Qdrant-pdf-images\",  # Local mode with in-memory storage only\n",
    "    collection_name=\"my_documents\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_rag_prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rag chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.1)   #gpt-4  #gpt-3.5-turbo\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_chain.invoke(\"write an example code to close wmx3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in rag_chain.stream(\"write a sample code to initialize wmx3?\"): \n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test RAG func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, ['Write python code to Read a file.', 'Write python code to Process the data.', 'Write python code to Save the result.'])\n",
      "(1, ['This is a general question about Python.'])\n",
      "(0, ['Write a python code to read data without numbers.'])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_code_sections(user_question):\n",
    "    \"\"\"\n",
    "    Extracts numbered sections of a user question based on specific starting phrases.\n",
    "    \n",
    "    If the question starts with 'Write a python code', 'Python code', or 'write python' (case insensitive),\n",
    "    it splits the question into paragraphs that start with numbers (e.g., 1., 2., 3.) and adds \n",
    "    'Write python code to ' before each paragraph, removing the numbers. If the question does not start \n",
    "    with the specified phrases or does not contain numbered lists, the entire question is saved into a single \n",
    "    element array. If the question does not start with the specified phrases, NoCoder is set to 1.\n",
    "    \n",
    "    Args:\n",
    "        user_question (str): The user's question.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: NoCoder (int), an array of strings with each element containing a code instruction or the entire question.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    NoCoder = 0\n",
    "    # Check if the input starts with the specified prefixes\n",
    "    if re.match(r'(?i)^(Write a python code|Python code|write python)', user_question):\n",
    "        # Find all numbered paragraphs\n",
    "        paragraphs = re.findall(r'(\\d+\\.\\s*)(.*)', user_question)\n",
    "        if paragraphs:\n",
    "            # Add 'Write python code to ' and remove numbers\n",
    "            for _, para in paragraphs:\n",
    "                result.append(f'Write python code to {para.strip()}')\n",
    "        else:\n",
    "            # Save the entire question to the array\n",
    "            result.append(user_question)\n",
    "    else:\n",
    "        # Save the entire question to the array and set NoCoder to 1\n",
    "        result.append(user_question)\n",
    "        NoCoder = 1\n",
    "    \n",
    "    return NoCoder, result\n",
    "\n",
    "# Example usage\n",
    "user_question1 = \"\"\"write python code to:\n",
    "1. Read a file.\n",
    "2. Process the data.\n",
    "3. Save the result.\"\"\"\n",
    "user_question2 = \"This is a general question about Python.\"\n",
    "user_question3 = \"Write a python code to read data without numbers.\"\n",
    "\n",
    "print(extract_code_sections(user_question1))\n",
    "print(extract_code_sections(user_question2))\n",
    "print(extract_code_sections(user_question3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Initialize the OpenAI client with your API key\n",
    "client = openai.OpenAI(api_key='')\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  temperature=0,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message['content'].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='In the realm of code, a concept profound,\\nRecursion dances, with elegance bound.\\nA function calls itself, a loop of delight,\\nUnraveling problems, layer by layer, taking flight.\\n\\nLike a mirror reflecting an image so true,\\nRecursion looks back, revealing a clue.\\nDividing a task into smaller bits,\\nIt tackles complexity, piece by tiny bits.\\n\\nThrough branches and loops, it ventures on,\\nA journey of beauty, until it is done.\\nWith elegance and grace, it weaves its spell,\\nUnraveling mysteries, the tale it tells.\\n\\nSo embrace the recursive, a friend so dear,\\nIn the world of programming, have no fear.\\nFor with each call, a problem unties,\\nRecursion whispers, \"In elegance lies.\"', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "# client = openai.OpenAI(api_key='' )\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-demo-IMu3vKF7-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
